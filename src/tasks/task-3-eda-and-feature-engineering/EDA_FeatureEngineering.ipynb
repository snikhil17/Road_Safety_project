{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA_FeatureEngineering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XlX0mMrtxqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e29ae0-c391-4026-d474-129ce767fe75"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 80 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCFw18kItz4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7564a6-290e-4a1f-ae75-32c58a4c379c"
      },
      "source": [
        "!pip install pywaffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pywaffle\n",
            "  Downloading pywaffle-0.6.3-py2.py3-none-any.whl (526 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 102 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 133 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 143 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 153 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 174 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 184 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 194 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 204 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 225 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 235 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 256 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 266 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 276 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 286 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 296 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 307 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 317 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 327 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 337 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 348 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 358 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 368 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 378 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 389 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 399 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 409 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 419 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 430 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 440 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 450 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 460 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 471 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 481 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 491 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 501 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 512 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 522 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 526 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pywaffle) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pywaffle) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pywaffle) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pywaffle) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pywaffle) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pywaffle) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->pywaffle) (1.15.0)\n",
            "Installing collected packages: pywaffle\n",
            "Successfully installed pywaffle-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHDA9zmJJVfk"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngOXtkbXJbmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99a8d77-e6cc-4a55-aa30-1859bd10c902"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "from dateutil.parser import parser\n",
        "\n",
        "from category_encoders import TargetEncoder,OneHotEncoder,HashingEncoder\n",
        "\n",
        "from category_encoders import TargetEncoder,OneHotEncoder,OrdinalEncoder,HashingEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from pywaffle import Waffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmRCaDj-Isv1"
      },
      "source": [
        "## **Reading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf9Vrjj7GqLH"
      },
      "source": [
        "def conv_to_df(data_path, *kwargs):\n",
        "\n",
        "    file_format = data_path.split(\".\")[1]\n",
        "\n",
        "    if file_format == \"csv\":\n",
        "        return pd.read_csv(data_path)\n",
        "\n",
        "    elif file_format == \"xlsx\":\n",
        "        return pd.read_excel(data_path, index_col=0)\n",
        "\n",
        "    elif file_format == \"txt\":\n",
        "        fileHandle = open(data_path, 'r', encoding='utf-8-sig')\n",
        "\n",
        "        rows = list(fileHandle)\n",
        "\n",
        "        keys = [row.strip() for row in rows[0].split(\"|\")]\n",
        "\n",
        "        df_dict = {k: [] for k in keys}\n",
        "\n",
        "        with open(data_path, 'r', encoding='utf-8-sig') as infh:\n",
        "            reader = csv.reader(infh, delimiter='|')\n",
        "            for ind, row in enumerate(reader):\n",
        "\n",
        "                if ind == 0:\n",
        "                    continue\n",
        "\n",
        "                else:\n",
        "                    for key, value in zip(df_dict.keys(), row):\n",
        "                        df_dict[key].append(value)\n",
        "\n",
        "        return pd.DataFrame(df_dict)\n",
        "\n",
        "    elif file_format == \"json\":\n",
        "\n",
        "        with open(data_path) as datafile:\n",
        "            data = json.load(datafile)\n",
        "            dataframe = pd.DataFrame(data)\n",
        "        return dataframe\n",
        "    \n",
        "    elif file_format == \"tsv\":\n",
        "        return pd.read_csv(data_path, sep=\"\\t\")\n",
        "\n",
        "    else:\n",
        "        resp = requests.get(data_path, params = params)\n",
        "\n",
        "        if resp.status_code == 200:\n",
        "            resp_dict = json.loads(resp.text)\n",
        "\n",
        "            headers = [\"trackName\", \"releaseDate\", \"collectionName\", \"trackPrice\", \"trackNumber\"]\n",
        "\n",
        "            df_dict = {k: [] for k in headers}\n",
        "\n",
        "            for track in resp_dict[\"results\"]:\n",
        "                try:\n",
        "                    df_dict[\"trackName\"].append(track[\"trackName\"])\n",
        "\n",
        "                    df_dict[\"releaseDate\"].append(track[\"releaseDate\"])\n",
        "\n",
        "                    df_dict[\"collectionName\"].append(track[\"collectionName\"])\n",
        "\n",
        "                    df_dict[\"trackPrice\"].append(track[\"trackPrice\"])\n",
        "\n",
        "                    df_dict[\"trackNumber\"].append(track[\"trackNumber\"])\n",
        "\n",
        "                except KeyError:\n",
        "                    continue\n",
        "\n",
        "            date_parser = parser()\n",
        "\n",
        "            releaseDates = [date_parser.parse(date).strftime(\"%m/%d/%Y, %H:%M:%S\") for date in df_dict[\"releaseDate\"]]\n",
        "\n",
        "            df_dict[\"releaseDate\"] = releaseDates\n",
        "\n",
        "            df = pd.DataFrame.from_dict(df_dict) \n",
        "\n",
        "        return df   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGNs0imZjV-_"
      },
      "source": [
        "def df_info(df, info, *kwargs):\n",
        "\n",
        "    print(\"Shape of Dataset: {}\\n\".format(df.shape))\n",
        "\n",
        "    print(\"Top {} Rows :\\n {}\\n\".format(kwargs[0], df.head(kwargs[0])))\n",
        "\n",
        "    print(\"DataFrame Data Types:\\n {} \\n\".format(df.dtypes))\n",
        "\n",
        "    print(\"DataFrame Information: \\n{}\\n\".format(df.info))\n",
        "\n",
        "    print(\"Null Values Per Column: \\n{}\\n\".format(df.isnull().sum()))\n",
        "\n",
        "    print(\"DataFrame Description: \\n{}\\n\".format(df.describe()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EnPfXmgI1mE"
      },
      "source": [
        "## **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsdDvzbUI9wz"
      },
      "source": [
        "#Converting Categorical values to Numerical values\n",
        "def transform_categorical_data(train,validate,test,cat_dict,y):\n",
        "  if \"One-Hot Encoding\" in cat_dict.keys():\n",
        "    cols=cat_dict['One-Hot Encoding']\n",
        "    OHE = OneHotEncoder(cols=cols)\n",
        "    train = OHE.fit_transform(train)\n",
        "    validate = OHE.transform(validate)\n",
        "    test = OHE.transform(test) \n",
        "\n",
        "  if \"Label Encoding\" in cat_dict.keys():\n",
        "    cols=cat_dict['Label Encoding']\n",
        "    LE = LabelEncoder()\n",
        "    for col in cols:\n",
        "        train[col]=LE.fit_transform(train[col])\n",
        "        validate[col]=LE.transform(validate[col])\n",
        "        test[col]=LE.transform(test[col])\n",
        "  \n",
        "  if \"Target Encoding\" in cat_dict.keys():\n",
        "    cols=cat_dict['Target Encoding']\n",
        "    TE = TargetEncoder(cols=cols)\n",
        "    TE.fit(train,y)\n",
        "    train= TE.transform(train)\n",
        "    validate=TE.transform(validate)\n",
        "    test=TE.transform(test)\n",
        "\n",
        "  if \"Hash Encoding\" in cat_dict.keys():\n",
        "    cols=cat_dict['Hash Encoding']\n",
        "    HE = HashingEncoder(cols=cols)\n",
        "    train= HE.fit_transform(train)\n",
        "    validate=HE.transform(validate)\n",
        "    test=HE.transform(test)\n",
        "\n",
        "\n",
        "  return train,test,validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7jlb03YJFIi"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZ-OmpFJIf_"
      },
      "source": [
        "# In the Capping step, we convert the values above the max value to the max value\n",
        "# And those below the min value to the min value\n",
        "\n",
        "def detect_and_remove_outliers(df,type,col):\n",
        "  if type == \"Normal\":\n",
        "    h = df[col].mean()+3*df[col].std()\n",
        "    l = df[col].mean()-3*df[col].std()\n",
        "    df[col]= np.where(df[col]>h,h, np.where(df[col]<l,l,df[col])) #Capping step\n",
        "  \n",
        "  if type == \"Skew\":\n",
        "    p25=df[col].quantile(0.25)\n",
        "    p75=df[col].quantile(0.75)\n",
        "    iqr=p75 - p25\n",
        "    h = p75 + 1.5*iqr\n",
        "    l = p25 - 1.5*iqr\n",
        "    df[col]= np.where(df[col]>h,h, np.where(df[col]<l,l,df[col])) #Capping step\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNuO8ghgKz6S"
      },
      "source": [
        "def transform_date(df,col):\n",
        "  date_dict={\"Day\":[],\"Month\":[],\"Year\":[]}\n",
        "  \n",
        "  for val in col:\n",
        "    val=str(val)\n",
        "    date = val.split(\"/\")\n",
        "    date_dict[\"Day\"].append(date[0])\n",
        "    date_dict[\"Month\"].append(date[1])\n",
        "    date_dict[\"Year\"].append(date[2])\n",
        "  \n",
        "  date_df=pd.DataFrame(date_dict,columns=[\"Day\",\"Month\",\"Year\"])\n",
        "  df=df.join(date_df)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvrlsYRzJJd5"
      },
      "source": [
        "## **Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5HK_IszJPt7"
      },
      "source": [
        "def df_plots(df, plot_, *kwargs):\n",
        "    if plot_ == \"box\":\n",
        "        if not len(kwargs):\n",
        "            df.boxplot(figsize=(20,20))\n",
        "        else:\n",
        "            df.boxplot(figsize=(20,20), column=kwargs[0])\n",
        "    \n",
        "    elif plot_ == \"corr\":\n",
        "\n",
        "        plt.figure(figsize=(20, 20))\n",
        "\n",
        "        heatmap = sns.heatmap(df.corr(), vmin=0, vmax=1, annot=True, cmap='Blues')\n",
        "        heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18});\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    elif plot_ == \"waffle\":\n",
        "      col_vals = train[kwargs[0]].value_counts()\n",
        "      fig = plt.figure(\n",
        "          FigureClass = Waffle,\n",
        "          rows = 5,\n",
        "          columns = 10,\n",
        "          values = col_vals,\n",
        "          title={\n",
        "              'label': 'Count of {}'.format(kwargs[0]),\n",
        "              'loc':'center',\n",
        "              'size':20\n",
        "              },\n",
        "              labels=[\"{}[{}]\".format(i,v) for i,v in enumerate(col_vals)],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScXH63MRuuzB"
      },
      "source": [
        "def feature_plot(model,train,type):\n",
        "  if type ==\"Linear Regression\":\n",
        "    coef=sorted(zip(model.coef_,train.columns),reverse=True)\n",
        "    coef_df=pd.DataFrame(coef,columns=[\"Values\",\"Features\"])\n",
        "    sns.barplot(x=\"Values\",y=\"Features\",data=coef_df)\n",
        "  else:\n",
        "    features=sorted(zip(model.feature_importances_,train.columns),reverse=True)\n",
        "    features_df=pd.DataFrame(features,columns=[\"Values\",\"Features\"])\n",
        "    sns.barplot(x=\"Values\",y=\"Features\",data=features_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}